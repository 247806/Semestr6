\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{graphicx}
%{Informatyka stosowana 2020, I st., semestr VI}


\author{
	{Dominik Gałkowski, 247659} \\
	{Jan Śladowski, 247806}\\ 
{Prowadzący: dr inż. Marcin Kacprowicz}
}

\title{Komputerowe systemy rozpoznawania 2024/2025\\Projekt 1. Klasyfikacja dokumentów tekstowych}
\begin{document}
\maketitle


\section{Cel projektu}
\indent Celem projektu jest przygotowanie aplikacji, która będzie dokonywała klasyfikacji zbioru dokumentów tekstowych metodą k-NN. Jej zadaniem będzie przydzielenie obiektu do odpowiedniej klasy. W trakcie działania programu konieczne będzie dokonanie ekstrakcji wektorów cech z artykułów dostępnych pod linkiem: 
\url{https://archive.ics.uci.edu/dataset/137/reuters+21578+text+categorization+collection}. \\

\section{Klasyfikacja nadzorowana metodą $k$-NN.  Ekstrakcja cech, wektory cech}
Metoda k-NN (k-Nearest Neighbors) jest algorytmem leniwym, co oznacza, że nie tworzy wewnętrznej reprezentacji danych uczących, tylko przechowuje wszystkie wzorce uczące. Dopiero po pojawieniu się wzorca testowego, dla którego wyznaczana jest odległość względem wszystkich wzorców uczących, algorytm poszukuje rozwiązania. \cite{knn}. Algorytm k-NN wymaga dwóch kluczowych parametrów, metryki, za pomocą, której wyznacza odległości obiektu testującego od wszystkich wzorców uczących oraz liczby sąsiadów k, czyli elementów do których badany element ma najbliżej. Decyzja klasyfikacyjna opiera się na najczęstszej klasie wśród k najbliższych sąsiadów. W przypadku naszego projektu odległość pomiędzy obiektami oznacza skalę podobieństwa tekstów.

W projekcie ekstrakcja cech charakterystycznych tekstu jest dokonywana poprzez stworzenie wektora cech, opisanego na podstawie następujących cech:
\begin{enumerate}
    \item Długość tekstu - cecha ta oznacza liczbę słów, z których składa się dany artykuł, co pozwala na porównanie długości różnych tekstów.
        \begin{equation}
            len = \sum_{i=0}^{n} x_i
        \end{equation}
        gdzie \( x \) = liczba liter \( \geq 3 \), \( n \) = liczba słów w tekście.
    \item Dominująca waluta - cecha ta reprezentowana jest poprzez nazwę waluty, ze zbioru walut kluczowych, która pojawia się najczęściej w badanym artykule. Na przykład w przypadku, gdy w badanym tekście pojawi się dwukrotnie słowo "U.S. Dollar" i tylko raz "Japanese Yen" to dla tej cechy zostanie zwrócona wartość tekstowa "U.S. Dollar".
        \begin{equation}
            w = \arg\max_{w \in W} f(w)
        \end{equation}
        gdzie W - zbiór walut kluczowych, \( f(w) \)  - liczba wystąpień waluty \( w \) w tekście.
    \item Nazwy miejsca - cecha ta jest reprezentacją tekstową wszystkich miejsc, np. nazw miast lub regionów pojawiających się ze zbioru miejsc kluczowych. Przykład: "AMR Corp will hold a press conference this morning in New York at 0900 EST, a company spokesman said." wynikiem dla tego cytatu będzie zbiór \( M' = \{ \text{New York} \} \). 
        \begin{equation}
            M' =  x \in M  \land x \in T
        \end{equation}
        gdzie M - zbiór miejsc kluczowych, T - zbiór słów znajdujących się w tekście, \( x \) = liczba liter \( \geq 3 \).
    \item Liczba unikalnych słów - cecha oznaczająca wystąpienia słów unikalnych, czyli takich, które nie pojawiąją się więcej niż jeden raz w tekście. Przykład: "AMR Corp will hold a press conference this morning in New York at 0900 EST, a company spokesman said. And the next week also in New York", słowa "New York" nie zostaną zliczone.
        \begin{equation}
            uk = \mid x : x \in T \land f(x) = 1 \mid
        \end{equation}
        gdzie T - zbiór słów znajdujących się w tekście, \( f(x)\)  - funkcja zwracająca liczbę wystąpień słowa x w tekście, \( x \) = liczba liter \( \geq 3 \).
    \item Średnia długość słowa - cecha opisująca średnią długość słów w badanym tekście.
     \begin{equation}
            al = \frac{\sum_{i=0}^{m} a_i}{\sum_{i=0}^{n} x_i}
        \end{equation}
        gdzie \( a_i \) - litera, \( x \) - liczba liter \( \geq 3 \), \( n \) = liczba słów w tekście, \( m \) = liczba liter w tekście.
    \item Liczba słów kluczowych w pierwszych 3 zdaniach - cecha ta oznacza bezwględną liczbę wystąpień słów ze zbioru słów kluczowych w pewnym fragmencie tekstu (pierwsze 3 zdania).
        \begin{equation}
            fw = \ \mid x : x \in K \wedge x \in T_{\text{y}} \mid
        \end{equation}
        gdzie K - zbiór słów kluczowych, \( T_y \) - zbiór słów znajdujący się w pierwszych trzech zdaniach tekstu, \( x\) = liczba liter \( \geq 3 \).
    \item Liczba słów zaczynających się wielką literą - cecha ta oznaczą liczbę wystąpień słów zaczynających się wielką literą, nie uzwlędniając przy tym słów rozpoczynających nowe zdanie.
        \begin{equation}
            bw = \sum_{i=0}^{n} x_i
        \end{equation}
        gdzie \( x \) = słowo zaczynające się wielką literą, \( n \) = liczba słów zaczynających się wielka literą w tekście
    \item Pierwsze kluczowe słowo w tekście - cecha opisująca pierwsze znalezione słowo znajdujące się w zbiorze słów kluczowych. Przykład: "AMR Corp will hold a press conference this morning in New York at 0900 EST, a company spokesman said." wynikiem dla tego cytatu będzie \(x_{first} \) = New York.
       \begin{equation}
            x_{first} = \min \{x: x \in K \land x \in T \}
        \end{equation}
        gdzie K - zbiór słów kluczowych, T - zbiór słów znajdujących się w tekście, \( x \) = liczba liter \( \geq 3 \).
    \item Liczba słów kluczowych - cecha ta oznacza bezwzględną liczbę wystąpień słów ze zbioru słów kluczowych. 
        \begin{equation}
            kw = \ \mid x : x \in K \land x \in T \mid
        \end{equation}
        gdzie K - zbiór słów kluczowych, T - zbiór słów znajdujących się w tekście, \( x \) = liczba liter \( \geq 3 \).
    \item Względna liczba słów kluczowych - cecha która reprezentuje stosunek słów kluczowych do długości całego tekstu. 
        \begin{equation}
            rw = \frac{ \mid x : x \in K \land x \in T \mid}{ \sum_{i=0}^{n} x_i}
        \end{equation}
       gdzie K - zbiór słów kluczowych, \( x \) = liczba liter \( \geq 3 \), T - zbiór słów znajdujących się w tekście, \( n \) = liczba słów w tekście
    \item Nazwiska - cecha ta jest reprezentacją tekstową wszystkich nazwisk pojawiających się ze zbioru nazwisk kluczowych. Przykład: "Wallis was quoted as saying the Reagan Administration wants Japanese cooperation so the White House can ensure any U.S." wynikiem dla tego cytatu będzie zbiór \( N' = \{ \text{Reagan} \} \).
    \begin{equation}
            N' =  x \in N \land x \in T
        \end{equation}
        gdzie N - zbiór nazwisk kluczowych, T - zbiór słów znajdujących się w tekście, \( x \) = liczba liter \( \geq 3 \).
\end{enumerate}

Wektor cech będzie miał postać: 
        \begin{equation}
          v = [c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11]
        \end{equation}


\section{Miary jakości klasyfikacji}
W celu określenia jakości przeprowadzonej klasyfikacji należy skorzystać z czterech miar jakości. W trakcie omawiania tej sekcji będziemy się posługiwać symbolami, które będą oznaczać klasy, do których można przypisać dany tekst (J - Japonia, F - Francja, W - Niemcy Zachodnie, C - Kanada, U - USA, UK - Wielka Brytania). 

\subsection{Dokładność (Accuracy)}
Dokładność to miara, która określa jaka część obiektów, ze wszystkich zaklasyfikowanych, została zaklasyfikowana poprawnie. Dokładność jest obliczana dla wszystkich klas jednocześnie i przyjmuje wartości z zakresu \([0, 1]\). Wyższa wartość dokładności oznacza, że ogólny procent poprawnie sklasyfikowanych obiektów jest większy, co sugeruje, że skuteczność klasyfikatora jest większa.
\begin{equation}
    ACC = \frac {TP}{TP + N}
\end{equation}
gdzie \(ACC\) - accuracy, \(TP\) - liczba wszystkich poprawnie sklasyfikowanych tekstów, \(N\) - liczba niepoprawnie sklasyfikowanych tekstów. \\
\subsection{Precyzja (Precision)}
Dzięki precyzji dowiadujemy się, ile wśród obiektów sklasyfikowanych do danej klasy jest rzeczywiście tej klasy. Precyzja jest obliczana dla wszystkich klas oddzielnie i przyjmuje wartości z zakresu \([0, 1]\). Im wyższy współczynnik precyzji, tym mniej błędnych klasyfikacji do danej klasy.
\begin{equation}
    PPV_x = \frac {TP_x}{TP_x + N_x}
\end{equation}
gdzie \(PPV_x\) - precision dla danej klasy \(x\), \(TP_x\) - liczba poprawnie sklasyfikowanych tekstów klasy \(x\), \(N_x\) - liczba niepoprawnie sklasyfikowanych  tekstów do klasy \(x\), \(x \in \{ \text{C, J, U, F, W, UK} \}\).
\subsection{Czułość (Recall)}
Czułość opisuje jaki jest udział poprawnie sklasyfikowanych obiektów wśród wszystkich obiektów tej klasy. Czułość jest obliczana dla wszystkich klas oddzielnie i przyjmuje wartości z zakresu \([0, 1]\). Wyższa wartość czułości oznacza, że klasyfikator skuteczniej wykrywa wszystkie przypadki danej klasy, co oznacza zmniejszenie liczby pominiętych istotnych obiektów.
\begin{equation}
    TPR_x = \frac {TP_x}{TP_x + NF_x}
\end{equation}
gdzie \(TPR_x\) - recall dla danej klasy \(x\), \(TP_x\) - liczba poprawnie sklasyfikowanych tekstów klasy \(x\), \(NF_x\) - liczba tekstów klasy \(x\), które zostały przypisane do innej klasy, \(x \in \{ \text{C, J, U, F, W, UK} \}\). 
\subsection{F1}
F1 to średnia harmoniczna pomiędzy precyzją a czułością, pozwalająca ocenić równowagę między nimi.  F1 jest obliczana dla wszystkich klas oddzielnie i przyjmuje wartości z zakresu \([0, 1]\). Im wyższa wartość miary F1, tym lepsza równowaga pomiędzy precyzją, a czułością
\begin{equation}
    F1_x = \frac{2 \times PPV_x \times TPR_x}{PPV_x + TPR_x}
\end{equation}
gdzie \(F1_x\) - miara F1 dla danej klasy \(x\), \(x \in \{ \text{C, J, U, F, W, UK} \}\). 

\subsection{Przykład z wykorzystaniem miar jakości klasyfikacji}
Mamy trzy zbiory, na ich podstawie obliczymy accuracy oraz precision, recall i F1 dla tekstów przypisanych do klasy Japonii: 
\begin{enumerate}
    \item Zbiór tekstów przypisanych jako Japonia \( \{ \text{J, J, J, F, U} \} \).
    \item Zbiór tekstów przypisanych jako Francja \( \{ \text{F, F, F, J} \} \).
    \item Zbiór tekstów przypisanych jako USA \( \{ \text{U, U, F, F} \} \).
\end{enumerate}

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        - & \textbf{\(TP_X\)} & \textbf{\(N_X\)} & \textbf{\(NF_X\)} \\
        \hline
        \textbf{Japonia (J)}  & \( TP_J = 3 \) & \( N_J = 2 \) & \( NF_J = 1 \) \\
        \hline
        \textbf{Francja (F)}  & \( TP_F = 3 \) & \( N_F = 1 \) & \( NF_F = 3 \) \\
        \hline
        \textbf{USA (U)}      & \( TP_U = 2 \) & \( N_U = 2 \) & \( NF_U = 1 \) \\
        \hline
    \end{tabular}
    \caption{Wartości dla klasyfikacji tekstów}
\end{table}



gdzie \(TP_x\) - liczba poprawnie sklasyfikowanych tekstów klasy \(x\), \(N_x\) - liczba niepoprawnie sklasyfikowanych  tekstów do klasy \(x\), \(NF_x\) - liczba tekstów klasy \(x\), które zostały przypisane do innej klasy, \(x \in \{ \text{C, J, U, F, W, UK} \}\).

\begin{flushleft}
- \(TP = 3 + 3 + 2 = 8\) (suma wszystkich poprawnie sklasyfikowanych tekstów),\\
- \(N = 2 + 1 + 2 = 5\) (suma wszystkich tekstów przypisanych do niewłaściwej klasy).

\[
    ACC = \frac{TP}{TP + N} = \frac{8}{13} \approx 0.62
\]

- \(TP_J = 3\) (Liczba tekstów poprawnie sklasyfikowanych do Japonii),\\
- \(N_J = 2\) (Liczba tekstów niepoprawnie przypisanych do Japonii).

\[
    PPV_J = \frac{TP_J}{TP_J + N_J} =\frac{3}{5} = 0.6
\]

- \(TP_J = 3\) (Liczba tekstów poprawnie przypisanych do Japonii),\\
- \(NF_J = 1\) (Liczba tekstów klasy Japonia, które zostały błędnie przypisane do innej klasy).

\[
    TPR_J = \frac{TP_J}{TP_J + NF_J} = \frac{3}{4} = 0.75
\]
\[
    F1_J = \frac{2 \times PPV_J \times TPR_J}{PPV_J + TPR_J} = \frac{0.9}{1.35} \approx 0.67
\]

\end{flushleft}




\section{Metryki i miary podobieństwa tekstów w klasyfikacji}
Metoda klasyfikacji k-NN polega na znajdowaniu k najbliższych sąsiadów, kluczową rolę w tym procesie odgrywają metryki oraz miary, które są wykorzystywane do ustalenia stopnia zgodności pomiędzy obiektami. Metryki umożliwiają obliczenie odległości między wektorami liczbowymi. Natomiast w przypadku cech tekstowych, zanim będzie można obliczyć ich podobieństwo, należy dokonać ich transformacji na wartości liczbowe. Umożliwiają to miary, które określają podobieństwo między ciągami znaków.

\subsection{Metryki}
\begin{enumerate}
    \item Metryka euklidesowa - w celu obliczenia odległości \(\rho_E(v1, v2)\) między dwoma wektorami \(v1, v2\) należy obliczyć pierwiastek kwadratowy z sumy kwadratów różnic ich składowych zgodnie ze wzorem:
        \begin{equation}
      \rho_E(v1, v2) = \sqrt{\sum_{i=1}^{n} (v1_i \underset{m}{-} v2_i)^2}  
        \end{equation}
        gdzie \(n\) - liczba cech w wektorach.
        
    \item Metryka uliczna - w celu obliczenia odległości \(\rho_M(v1, v2)\) między dwoma wektorami \(v1, v2\) należy obliczyć sumę wartości bezwzględnych różnic cech zgodnie ze wzorem:
        \begin{equation}
          \rho_M(v1, v2) = \sum_{i=1}^{n} |v1_i \underset{m}{-} v2_i|
        \end{equation}
        gdzie \(n\) - liczba cech w wektorach.
        
    \item Metryka Czebyszewa - w celu obliczenia odległości \(\rho_C(v1, v2)\) między dwoma wektorami \(v1, v2\) należy obliczyć maksymalną wartość bezwzględnych różnic cech zgodnie ze wzorem:
        \begin{equation}
          \rho_C(v1, v2) = \max_{i = 1,...,n} |v1_i \underset{m}{-} v2_i|
        \end{equation}
        gdzie \(n\) - liczba cech w wektorach.
\end{enumerate}
gdzie 
\[
    v1_i \underset{m}{-} v2_i = 
    \begin{cases}
    v1_i - v2_i & \text{dla } v1_i, v2_i \in \mathbb{R} \\
    1 - sim_w(v1_i, v2_i) & \text{jeśli } v1_i, v2_i \text{ są tekstami}\\
    1 - sim_z(v1_i, v2_i) & \text{jeśli } v1_i, v2_i \text{ są zbiorami tekstów}
    \end{cases}
\]
gdzie \(v1_i\), \(v2_i\) - i-ta składowa wektorów cech \(v1\) oraz \(v2\),\\ \(sim_w\) - podobieństwo tekstów obliczone uogólnioną miarę n-gramów z ograniczeniami (pkt 4.2),\\ \(sim_z\) - podobieństwo zbiorów wyrazów obliczone miarą podobieństwa zdań (pkt 4.3). \\
W celu poprawnego przeprowadzenia obliczeń dla metryk należy uprzednio przeprowadzić normalizację cech wektórów, tak aby żadna z cech nie była dominująca. Wektory zostaną znormalizowane za pomocą metody min-max scaling do zakresu [0, 1].\\
Załóżmy, że mamy dwa wektory cech:
\begin{enumerate}
    \item \(v1 = (1, 2, 30)\)
    \item \(v2 = (4, 6, 3)\)
\end{enumerate}
\[
    c_{\min} = 1, \quad c_{\max} = 30
\]
gdzie c to cecha składowa wektora \(v1\) lub \(v2\). \\
Aby otrzymać znormalizowane wartości należy skorzystać z wzoru:
\begin{equation}
    c' = \frac{c - c_{min}}{c_{max} - c_{min}}
\end{equation}
Znormalizowana postać wektorów:
\begin{enumerate}
    \item \(v1' = (0.000, 0.034, 1.000)\)
    \item \(v2' = (0.103, 0.172, 0.069)\)
\end{enumerate} 
Z wykorzystaniem powyższych wektorów otrzymujemy:
\[
     \rho_E(v1, v2) = \sqrt{(0.000 - 0.103)^2 + (0.034 - 0.172)^2 + (1.000 - 0.069)^2} = 
\]
\[
       = \sqrt{0.946} \approx 0.947
\]
\[
    \rho_M(v1, v2) = |0.000 - 0.103| + |0.034 - 0.172| + |1.000 - 0.069| = 1.172
\]
\[
    \rho_C(v1, v2) = \max(|0.000 - 0.103|, |0.034 - 0.172|, |1.000 - 0.069|) = 
\]
\[
     = \max(0.103, 0.138, 0.931) = 0.931
\]
\\
Metryka euklidesowa, uliczna oraz Czebyszewa przyjmują wartości z zakresu \([0, \infty)\). Im otrzymana wartość jest mniejsza, tym oba wektory cech są do siebie bardziej podobne.

\subsection{Uogólniona miara n-gramów z ograniczeniami}
Wykorzystując uogólnioną miarę n-gramów z ograniczeniami możemy pewną liczbą wyrazić podobieństwo dwóch łańcuchów znaków. Ta miara przyjmuje wartości z zakresu \([0,1]\), przy czym wartości wyższe oznaczają większe podobieństwo pomiędzy badanymi łańcuchami znaków. Krańcowe wartości oznaczają: 0 – różne łańcuchy znaków, 1 - identyczne łańcuchy znaków. Przekształcenie cech tekstowych na wartości numeryczne umożliwia obliczenie ich wpływu na odległości między wektorami. Odległość pomiędzy dwoma łańcuchami znaków możemy określić poprzez:
\begin{equation}
    d = 1 - sim_w(s1, s2)
\end{equation}
gdzie \(sim_w(s1,s2)\) oznacza uogólnioną miarę n-gramów z ograniczeniami
\begin{equation}
    \mu_N(s1, s2) = f(N, n_1, n_2) \sum_{i=n_1}^{n_2} \sum_{j=1}^{N(s1) - i + 1} h(i, j)
\end{equation}
gdzie \( s1, s2\) - cechy, które przyjmują wartości tekstowe;
\begin{equation} 
f(N, n_1, n_2) = \frac{2}{(N - n_1 + 1)(N - n_1 + 2) - (N - n_2 + 1)(N - n_2)}
\end{equation}
wyraża odwrotność liczby możliwych podciagów o długosciach od \(n_1\) do \(n_2\)
\(1 \leq n_1 \leq n_2 \leq N\); \\
\(h(i,j) = 1\) jeśli \(i\)-elementowy podciag w słowie s1 zaczynajacy sie od \(j\)-tej
pozycji w słowie \(s_1\) pojawia sie przynajmniej raz w słowie \(s_2\) (inaczej
\(h(i,j) = 0\));\\
\(N(s1), N(s2)\) - oznaczają liczbę liter w słowach \( s1\) i \(s2\);\\
\(N = \max \{N(s1), N(s2)\}\).\\


Załóżmy, że mamy dwa wektory cech (wektory powinny być znormalizowane, ale na potrzeby tego przykładu zostało to pominięte):
\begin{enumerate}
    \item \(v1 = (1, KARTON, 3)\)
    \item \(v2 = (4, KARNISZ, 3)\)
\end{enumerate}
Traktując drugą cechę jako łańcuchy znaków, mamy:
\[
s_1 = \{K, A, R, T, O, N\}, \quad s_2 = \{K, A, R, N, I, S, Z\}
\]
czyli:\\
\[
N(s_1) = 6, N(s_2) = 7, N = \max \{N(s_1), N(s_2)\} = 7
\]
Obliczając podobieństwo przyjmujemy \(n_1 = 2\) oraz \(n_2 = 3\) 
\[
    \mu_N(s_1, s_2) = \frac{2}{(7 - 2 + 1)(7 - 2 + 2) - (7 - 3 + 1)(7 - 3)} \sum_{i=2}^{3} \sum_{j=1}^{6 - i + 1} h(i, j) = 
 \]
 \[
     = \frac{2 + 1}{11} \approx 0.27.
 \]
 ponieważ w \(s_2\) występują poniższe podciągi z \(s_1\)\\
 2 - 2-elementowe KA, AR;\\
 1 - 3-elementowy KAR;\\
 \\Wówczas odległość euklidesowa pomiędzy wektorami wynosi:
 \[
     \rho_E(v1, v2) = \sqrt{(1-4)^2 + (1 - 0.27)^2 + (3-3)^2} = \sqrt{9 + 0.73 + 0} = 
\] 
\[
     = \sqrt{9.73} \approx 3.12
\] 

\subsection{Miara podobieństwa zdań}
Wykorzystując uogólnioną miarę podobieństwa zdań, traktowanych jako zbiory (a nie ciągi) wyrazów, możemy pewną liczbą wyrazić stopień podobieństwa pomiędzy dwoma zbiorami słów. Miara ta przyjmuje wartości z zakresu \([0,1]\), gdzie wyższe wartości oznaczają większe podobieństwo między porównywanymi zbiorami. Krańcowe wartości interpretujemy następująco: 0 – zbiory zupełnie różne, 1 – zbiory identyczne pod względem zestawu użytych słów. Przekształcenie cech tekstowych na wartości numeryczne umożliwia analizę ich wpływu na odległości w przestrzeni wektorowej. Odległość pomiędzy dwoma zbiorami wyrazów możemy określić za pomocą następującej formuły:
\begin{equation}
    d = 1 - sim_z(z1, z2)
\end{equation}
gdzie \(sim_z(z1,z2)\) oznacza miarę podobieństwa zdań\\
\begin{equation} 
\mu_{NZ}(z_1, z_2) = \frac{1}{N} \sum_{i=1}^{N(z_1)} \max_{j = 1, \ldots, N(z_1)} \mu_N(s_{1i}, s_{2j})
\end{equation}
gdzie:\\
 $s_{1i}$ – $i$-ty wyraz w zbiorze $z_1$;\\
 $s_{2j}$ – $j$-ty wyraz w zbiorze $z_2$;\\
 $\mu_N(s_{1i}, s_{2j})$ – wartość funkcji (22) dla $(s_{1i}, s_{2j})$;\\
 $N(z_1), N(z_2)$ – liczba słów w zbiorach $z_1$, $z_2$;\\
 $N = \max\{N(z_1), N(z_2)\}$.\\
Załóżmy, że mamy dwa wektory cech (wektory powinny być znormalizowane, ale na potrzeby tego przykładu zostało to pominięte):
\begin{enumerate}
    \item \(v_1 = (1, \text{ kot je}, 3)\)
    \item \(v_2 = (4, \text{ kot pije wodę}, 3)\)
\end{enumerate}
Traktując drugą cechę jako zbiór wyrazów, mamy:
\[
z_1 = \{\text{kot}, \text{je}\}, \quad z_2 = \{\text{kot}, \text{pije}, \text{wodę}\}
\]
czyli:
\[
N(z_1) = 2, \quad N(z_2) = 3, \quad N = \max\{N(z_1), N(z_2)\} = 3
\]
Wartość podobieństwa zbiorów:
\[
\mu_{NZ}(z_1, z_2) = \frac{1}{3}\sum_{i=1}^{3} \max_{j = 1, 2} \mu_N(s_{1i}, s_{2j}) = \frac{1 + 0.2 + 0}{3} = 0.4
\]

gdzie
\[
\begin{aligned}
\max \{\mu_N(\text{kot}, \text{kot}), \mu_N(\text{je}, \text{kot})\} = 1.0 \\
\max \{\mu_N(\text{kot}, \text{pije}), \mu_N(\text{je}, \text{pije})\} = 0.2 \\
\max \{\mu_N(\text{kot}, \text{wodę}), \mu_N(\text{je}, \text{wodę})\} = 0 \\
\end{aligned}
\]
Wówczas odległość euklidesowa pomiędzy wektorami wynosi:
\[
\rho_E(v_1, v_2) = \sqrt{(1 - 4)^2 + (1 - 0.4)^2 + (3 - 3)^2} = \sqrt{9 + 0.36 + 0} = \sqrt{9.25} \approx 3.06
\]

\section{Wyniki klasyfikacji dla różnych parametrów wejściowych}
W niniejszej sekcji przeprowadzono eksperymenty polegające na przeprowadzeniu klasyfikacji tekstów dla zbioru składającego się z 13441 artykułów, przy czym są to artykuły, które posiadają etykietę tylko jednego kraju (USA, UK, Kanada, Francja, Niemcy Zachodnie, Japonia) oraz nieposiadają pustego tekstu. Celem tego badania było przeprowadzenie analizy wpływu parametrów wejściowych algorytmu k-najbliższych sąsiadów na skuteczność klasyfikatora opisaną jako dokładność (accuracy). \\
Badanie przeprowadzono w oparciu o różne warianty konfiguracji parametów wejściowych, zgodnie z punktami 3–8 zawartymi w opisie Projektu 1. Uwzględniono m.in. różne wartości parametru \(k\), różny podział zbioru pomiędzy uczący, a testowy oraz różne metryki. Eksperymenty polegają na tym, że w każdym z nich będzie zmieniany tylko jeden parametr, którego wpływ będzie aktualnie badany.
Oznaczenia użyte w tabelach to: ACC - opisane w (13),  \( \text{PPV}_x \) - (14), \( \text{TPR}_x \) - (15), \( \text{F1}_x \) - (16), U - teksty o Stanach Zjednoczonych, UK - teksty o Wielkiej Brytanii, C - teksty o Kanadzie, J - teksty o Japonii, F - teksty o Francji, W - teksty o Niemczech Zachodnich.
\\
Przykładowy wektor z wyekstrahowanymi cechami:
\[
    v = [ 0.04584717607973422, dlrs, [ florida, florida], 0.09576427255985268,
\]
\[
     0.5597984105446793, 0.047619047619047616, 0.036312849162011177, florida,
\]
\[
     0.058823529411764705, 0.15584415584415584, [] ]
\]
\subsection{Różne wartości parametru \(k\)}
W poniższej tabeli przedstawiono wpływ różnych wartości parametru \(k\) na dokładność klasyfikacji tekstów. Eksperymenty przeprowadzono przy stałych pozostałych ustawieniach: podziale zbioru danych na 60\% zbioru uczącego i 40\% zbioru testowego, metryce euklidesowej oraz zakresie długości n-gramów od \(n_1 = 2\) do \(n_2 = 4\). \\
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
    \textbf{Parametr k} & \textbf{\(1\)} & \textbf{\(2\)} & \textbf{\(3\)} & \textbf{\(5\)}  & \textbf{\(9\)}  & \textbf{\(15\)} & \textbf{\(25\)} \\ \hline
    ACC [\%] & 85,53 & 85,53 & 88,23 & 88,94 & 89,27 & 89,14 & 88,84\\ \hline
    PPV\(_U\) & 0,9999 & 0,9999 & 0,9101 & 0,9093 & 0,9061 & 0,9047 & 0,9025\\ \hline
    TPR\(_U\) & 0,9310 & 0,9310 & 0,9640 & 0,9733 & 0,9796& 0,9794 & 0,9806\\ \hline
    F1\(_U\) & 0,9203 & 0,9203 & 0,9363 & 0,9402 & 0,9414& 0,9406 & 0,9399\\ \hline
    PPV\(_C\) & 0,4794 & 0,4794 & 0,6500 &  0,7222 & 0,7585& 0,7536& 0,7938\\ \hline
    TPR\(_C\) & 0,4646 & 0,4646 & 0,4800 &  0,4800& 0,4831& 0,4800& 0,4738\\ \hline
    F1\(_C\) & 0,4719 & 0,4719 & 0,5522 &  0,5767& 0,5902& 0,5865& 0,5934\\ \hline
    PPV\(_UK\) & 0,6799 & 0,6799 & 0,7692 & 0,8036& 0,8465& 0,8543& 0,8408\\ \hline
    TPR\(_UK\) & 0,6160 & 0,6160 & 0,6077 &  0,6105& 0,5939& 0,5829& 0,5691\\ \hline
    F1\(_UK\) & 0,6464 & 0,6464 & 0,6790 &  0,6939& 0,6981& 0,6929& 0,6787\\ \hline
    PPV\(_F\) & 0,6087 & 0,6087 & 0,7403 & 0,7600& 0,8000& 0,7746& 0,7123\\ \hline
    TPR\(_F\) & 0,5545 & 0,5545 & 0,5644 & 0,5644& 0,5545& 0,5446& 0,5149\\ \hline
    F1\(_F\) & 0,5803 & 0,5803 & 0,6404 &  0,6477& 0,6550& 0,6395& 0,5977\\ \hline
    PPV\(_W\) & 0,4769 & 0,4769 & 0,5870 & 0,6857& 0,8750& 0,9474& 0,8333\\ \hline
    TPR\(_W\) & 0,2403 & 0,2403 & 0,2093 & 0,1860& 0,1628& 0,1395& 0,0388\\ \hline
    F1\(_W\) & 0,3196 & 0,3196 & 0,3086 & 0,2927& 0,2745& 0,2432& 0,0741\\ \hline
    PPV\(_J\) & 0,7805 & 0,7805 & 0,8168 & 0,8168& 0,8168& 0,8116& 0,7870\\ \hline
    TPR\(_J\) & 0,8556 & 0,8556 & 0,8824 &  0,8824& 0,8824& 0,8984& 0,9091\\ \hline
    F1\(_J\) & 0,8163 & 0,8163 & 0,8483 &  0,8483& 0,8483& 0,8528& 0,8437\\ \hline
    \end{tabular}
    \caption{Wyniki miar przy badaniu wpływu liczby \(k\) na jakość klasyfikacji}
\end{table}
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Parametr k} & \textbf{\(40\)} & \textbf{\(65\)} & \textbf{\(100\)}\\ \hline
    ACC [\%]  & 88,42 & 88,08 & 87,50\\ \hline
    PPV\(_U\) & 0,8980& 0,8945 & 0,8887\\ \hline
    TPR\(_U\) & 0,9801& 0,9803 & 0,9803\\ \hline
    F1\(_U\) & 0,9372& 0,9355& 0,9323\\ \hline
    PPV\(_C\) & 0,7956& 0,7988& 0,7758\\ \hline
    TPR\(_C\) & 0,4431& 0,4154& 0,3938\\ \hline
    F1\(_C\) & 0,5692& 0,5466& 0,5224\\ \hline
    PPV\(_UK\) & 0,8120& 0,7960& 0,7860\\ \hline
    TPR\(_UK\) & 0,5608& 0,5497& 0,5276\\ \hline
    F1\(_UK\) & 0,6634& 0,6503& 0,6314\\ \hline
    PPV\(_F\) & 0,7188& 0,7241 & 0,7436\\ \hline
    TPR\(_F\) & 0,4554& 0,4158 & 0,2871\\ \hline
    F1\(_F\) & 0,5576& 0,5283 & 0,4143\\ \hline
    PPV\(_W\) & 1,0000& 1,0000 & 0,0000\\ \hline
    TPR\(_W\) & 0,0233& 0,0078& 0,0000\\ \hline
    F1\(_W\) & 0,0455& 0,0154& 0,0000\\ \hline
    PPV\(_J\) & 0,7907& 0,7870& 0,7778\\ \hline
    TPR\(_J\) & 0,9091& 0,9091& 0,8984\\ \hline
    F1\(_J\) & 0,8458& 0,8437& 0,8387\\ \hline
    \end{tabular}
    \caption{Wyniki miar przy badaniu wpływu liczby \(k\) na jakość klasyfikacji (cd.)}
\end{table}
\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{ksr/img/ACC - K.png}
    \caption{Zależność accuracy do parametru k}
    \label{fig:moj-obraz}
\end{figure}
% Na podstawie wyników można zaobserwować, że miara Accuracy rośnie wraz ze wzrostem parametru \(k\) do wartości \(k = 10\), osiągając maksimum równe 0{,}8924. Dalsze zwiększanie wartości \(k\) prowadzi jednak do spadku dokładności klasyfikatora. Może to świadczyć o nadmiernym uogólnieniu modelu przy zbyt dużej liczbie sąsiadów, co skutkuje mniejszą precyzją klasyfikacji.

\subsection{Różny podział zbioru pomiędzy uczący, a testowy}
W poniższej tabeli przedstawiono wpływ proporcji podziału zbioru na dokładność klasyfikacji tekstów. Eksperymenty przeprowadzono przy stałych pozostałych ustawieniach: \(k\) = 9, metryce euklidesowej oraz zakresie długości n-gramów od \(n_1 = 2\) do \(n_2 = 4\). Wartości w tabeli pod kolumną "Podział zbioru" opisują ile jest artykułów w zbiorze uczącym względem liczby wszystkich artykułów.

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c}
    \hline
    \textbf{Podział zbioru [\%]} & \textbf{\(10\)} & \textbf{\(30\)} & \textbf{\(50\)} & \textbf{\(70\)}  & \textbf{\(90\)} \\ \hline
    ACC [\%] & 87,91 & 88,74 & 89,17 & 89,27 & 88,80\\ \hline
    PPV\(_U\) & 0,8887 & 0,9009 & 0,9051 & 0,9072 & 0,9042\\ \hline
    TPR\(_U\) & 0,9803 & 0,9781 & 0,9785 & 0,9788 & 0,9804\\ \hline
    F1\(_U\) & 0,9323 & 0,9379 & 0,9404 & 0,9416 & 0,9408\\ \hline
    PPV\(_C\) & 0,8310 & 0,7650 & 0,7500 & 0,7770 & 0,7255\\ \hline
    TPR\(_C\) & 0,4104 & 0,4692 & 0,4877 & 0,4713 & 0,4512\\ \hline
    F1\(_C\) & 0,5495 & 0,5817 & 0,5910 & 0,5867 & 0,5564\\ \hline
    PPV\(_UK\) & 0,8046 & 0,8111 & 0,8590& 0,8390 & 0,8197\\ \hline
    TPR\(_UK\) & 0,5153 & 0,5757 & 0,5916 & 0,6324 & 0,5495\\ \hline
    F1\(_UK\) & 0,6283 & 0,6734 & 0,7007 & 0,7212 & 0,6579\\ \hline
    PPV\(_F\) & 0,7589 & 0,7807 & 0,8025 & 0,7358 & 0,8000\\ \hline
    TPR\(_F\) & 0,3761 & 0,5057 & 0,5159 & 0,5132 & 0,4615\\ \hline
    F1\(_F\) & 0,5030 & 0,6138 & 0,6280 & 0,6047 & 0,5854\\ \hline
    PPV\(_W\) & 0,7857 & 0,8333 & 0,8065 & 0,8421 & 0,7000\\ \hline
    TPR\(_W\) & 0,0379 & 0,1549 & 0,1553 & 0,1649 & 0,2121\\ \hline
    F1\(_W\) & 0,0724 & 0,2612 & 0,2604 & 0,2759 & 0,3256\\ \hline
    PPV\(_J\) & 0,8145 & 0,8333 & 0,8140 & 0,8140 & 0,8269\\ \hline
    TPR\(_J\) & 0,8571 & 0,8563 & 0,9013 & 0,9013 & 0,9149\\ \hline
    F1\(_J\) & 0,8353 & 0,8446 & 0,8554 & 0,8554 & 0,8687\\ \hline
    \end{tabular}
    \caption{Wyniki miar przy badaniu wpływu podziału zbiorów na jakość klasyfikacji}
\end{table}

% Wyniki wskazują na istotny wpływ proporcji podziału zbioru na dokładność klasyfikacji. W miarę zwiększania udziału zbioru uczącego w całości danych, skuteczność klasyfikatora rośnie, osiągając najwyższą wartość przy podziale 80\% danych do zbioru uczącego. Zwiększenie tego udziału powoduje, że model ma więcej danych do nauki, co przekłada się na lepsze dopasowanie do wzorców w danych. Z kolei mniejsze proporcje danych uczących prowadzą do gorszej efektywności, co może być wynikiem niedostatecznej liczby próbek w procesie treningu.

\subsection{Różne metryki}
W poniższej tabeli przedstawiono wpływ różnych metryk na dokładność klasyfikacji tekstów. Eksperymenty przeprowadzono przy stałych pozostałych ustawieniach: podziale zbioru danych na 60\% zbioru uczącego i 40\% zbioru testowego \(k = 9\) oraz zakresie długości n-gramów od \(n_1 = 2\) do \(n_2 = 4\). \\

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Parametr k} & \textbf{Euklidesowa} & \textbf{Uliczna} & \textbf{Czebyszewa}  \\ \hline
    ACC [\%] & 89,27 & 88,12 & 79,96\\ \hline
    PPV\(_U\) & 0,9061 & 0,8893 & 0,7988\\ \hline
    TPR\(_U\) & 0,9796& 0,9850 & 0,9998\\ \hline
    F1\(_U\)  & 0,9414& 0,9347 & 0,8881\\ \hline
    PPV\(_C\) & 0,7585& 0,7986 & 1,0000\\ \hline
    TPR\(_C\) &  0,4831& 0,3538 & 0,0092\\ \hline
    F1\(_C\) & 0,5902& 0,4904 & 0,0183\\ \hline
    PPV\(_UK\) & 0,8465& 0,8221 & 1,0000\\ \hline
    TPR\(_UK\) & 0,5939& 0,5746 & 0,0221\\ \hline
    F1\(_UK\) & 0,6981& 0,6764 & 0,0432\\ \hline
    PPV\(_F\) & 0,8000& 0,8679 & 0,0000\\ \hline
    TPR\(_F\) & 0,5545& 0,4554 & 0,0000\\ \hline
    F1\(_F\) & 0,6550& 0,5974 & 0,0000\\ \hline
    PPV\(_W\) & 0,8750& 0,7143 & 0,0000\\ \hline
    TPR\(_W\) & 0,1628& 0,0388 & 0,0000\\ \hline
    F1\(_W\) & 0,2745& 0,0735 & 0,0000\\ \hline
    PPV\(_J\) & 0,8168& 0,8289 & 0,8889\\ \hline
    TPR\(_J\) & 0,8824& 0,8289 & 0,0856\\ \hline
    F1\(_J\) & 0,8483 & 0,8289 & 0,1561\\ \hline
    \end{tabular}
    \caption{Wyniki miar przy badaniu wpływu metryk na jakość klasyfikacji}
\end{table}
% Wyniki wskazują na najlepszą skuteczność klasyfikatora przy zastosowaniu metryki euklidesowej, uzyskując miarę Accuracy równą 0{,}8864. Metryka uliczna, choć również dała zadowalający wynik (Accuracy = 0{,}8767), okazała się nieco mniej efektywna w porównaniu do metryki euklidesowej. Z kolei metryka Czybyszewa zwróciła najgorszy wynik.


\section{Dyskusja, wnioski, sprawozdanie końcowe}

Wyniki kolejnych eksperymentów wg punktów 2.-8. opisu projektu 1.  Każdorazowo
podane parametry, dla których przeprowadzana eksperyment. 
Wykresy (np. słupowe) i tabele wyników
obowiązkowe, dokładnie opisane w ,,captions'' (tytułach), konieczny opis osi i
jednostek wykresów oraz kolumn i wierszy tabel.\\ 

{**Ewentualne wyniki realizacji punktu 9. opisu Projektu 1., czyli ,,na ocenę 5.0'' i ich porównanie do wyników z
części obowiązkowej**.Dokładne interpretacje uzyskanych wyników w zależności od parametrów klasyfikacji
opisanych w punktach 3.-8 opisu Projektu 1. 
Omówić i wyjaśnić napotkane problemy (jeśli były). Każdy wniosek/problem powinien mieć poparcie
w przeprowadzonych eksperymentach (odwołania do konkretnych wyników: wykresów,
tabel). \\
\underline{Dla końcowej oceny jest to najważniejsza sekcja} sprawozdania, gdyż prezentuje poziom
zrozumienia rozwiązywanego problemu.\\

** Możliwości kontynuacji prac w obszarze systemów rozpoznawania, zwłaszcza w kontekście pracy inżynierskiej,
magisterskiej, naukowej, itp. **\\

\noindent {\bf Sekcja uzupełniona jako efekt zadań Tydzień 05 i Tydzień 06 wg Harmonogramu Zajęć
na WIKAMP KSR.}


\section{Braki w realizacji projektu 1.}
Wymienić wg opisu Projektu 1. wszystkie niezrealizowane obowiązkowe elementy projektu, ewentualnie
podać merytoryczne (ale nie czasowe) przyczyny tych braków. 


\begin{thebibliography}{0}
\bibitem{knn} Metoda k-NN \url{https://home.agh.edu.pl/~horzyk/lectures/miw/KNN.pdf} [dostęp: 28.03.2025r.]
\bibitem{tab} Wikipedia, Tablica pomyłek, \url{https://pl.wikipedia.org/wiki/Tablica_pomy%C5%82ek}. [dostęp: 28.03.2025r.]
\bibitem{niewiadomski08} A. Niewiadomski, Methods for the Linguistic Summarization of Data: Applications of Fuzzy Sets and Their Extensions, Akademicka Oficyna Wydawnicza EXIT, Warszawa, 2008.
\end{thebibliography}

Literatura zawiera wyłącznie źródła recenzowane i/lub o potwierdzonej wiarygodności,
możliwe do weryfikacji i cytowane w sprawozdaniu. 
\end{document}